{
    "name": "root",
    "gauges": {
        "MoveToTargetSimulated.Policy.Entropy.mean": {
            "value": 1.3996684551239014,
            "min": 1.3996684551239014,
            "max": 1.4210659265518188,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.Entropy.sum": {
            "value": 69962.4296875,
            "min": 69962.4296875,
            "max": 71448.890625,
            "count": 10
        },
        "MoveToTargetSimulated.Environment.EpisodeLength.mean": {
            "value": 156.83333333333334,
            "min": 7.389429530201342,
            "max": 156.83333333333334,
            "count": 6
        },
        "MoveToTargetSimulated.Environment.EpisodeLength.sum": {
            "value": 8469.0,
            "min": 8469.0,
            "max": 47892.0,
            "count": 6
        },
        "MoveToTargetSimulated.Step.mean": {
            "value": 499968.0,
            "min": 49998.0,
            "max": 499968.0,
            "count": 10
        },
        "MoveToTargetSimulated.Step.sum": {
            "value": 499968.0,
            "min": 49998.0,
            "max": 499968.0,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.006062194239348173,
            "min": -0.022282689809799194,
            "max": 0.663779079914093,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.ExtrinsicValueEstimate.sum": {
            "value": 4.734573841094971,
            "min": -101.052001953125,
            "max": 3982.67431640625,
            "count": 10
        },
        "MoveToTargetSimulated.Environment.CumulativeReward.mean": {
            "value": -0.02954698581662443,
            "min": -0.04123043309543448,
            "max": 0.0010978828510480512,
            "count": 6
        },
        "MoveToTargetSimulated.Environment.CumulativeReward.sum": {
            "value": -1.5955372340977192,
            "min": -102.18547582812607,
            "max": 6.542283909395337,
            "count": 6
        },
        "MoveToTargetSimulated.Policy.ExtrinsicReward.mean": {
            "value": -0.02954698581662443,
            "min": -0.04123043309543448,
            "max": 0.0010978828510480512,
            "count": 6
        },
        "MoveToTargetSimulated.Policy.ExtrinsicReward.sum": {
            "value": -1.5955372340977192,
            "min": -102.18547582812607,
            "max": 6.542283909395337,
            "count": 6
        },
        "MoveToTargetSimulated.Losses.PolicyLoss.mean": {
            "value": 0.02305578862860178,
            "min": 0.021250960790785027,
            "max": 0.02668085692838455,
            "count": 10
        },
        "MoveToTargetSimulated.Losses.PolicyLoss.sum": {
            "value": 0.11527894314300889,
            "min": 0.09549685937818139,
            "max": 0.13340428464192275,
            "count": 10
        },
        "MoveToTargetSimulated.Losses.ValueLoss.mean": {
            "value": 4.737547521168987e-05,
            "min": 4.737547521168987e-05,
            "max": 0.34397874207546314,
            "count": 10
        },
        "MoveToTargetSimulated.Losses.ValueLoss.sum": {
            "value": 0.00023687737605844936,
            "min": 0.00023687737605844936,
            "max": 1.3759149683018526,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.LearningRate.mean": {
            "value": 1.6339294553599997e-05,
            "min": 1.6339294553599997e-05,
            "max": 0.00028462425512524995,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.LearningRate.sum": {
            "value": 8.169647276799999e-05,
            "min": 8.169647276799999e-05,
            "max": 0.0012847104717631998,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.Epsilon.mean": {
            "value": 0.10544640000000001,
            "min": 0.10544640000000001,
            "max": 0.19487475,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.Epsilon.sum": {
            "value": 0.527232,
            "min": 0.500096,
            "max": 0.9282368000000002,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.Beta.mean": {
            "value": 0.00028177536000000003,
            "min": 0.00028177536000000003,
            "max": 0.0047442500250000005,
            "count": 10
        },
        "MoveToTargetSimulated.Policy.Beta.sum": {
            "value": 0.0014088768000000002,
            "min": 0.0014088768000000002,
            "max": 0.021419016319999998,
            "count": 10
        },
        "MoveToTargetSimulated.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "MoveToTargetSimulated.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1687590711",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Unity Projects\\ML Agents\\ML Agents\\venv\\Scripts\\mlagents-learn --run-id=IRL2 --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1687591133"
    },
    "total": 421.8930282,
    "count": 1,
    "self": 0.006196900000020378,
    "children": {
        "run_training.setup": {
            "total": 0.02972269999999999,
            "count": 1,
            "self": 0.02972269999999999
        },
        "TrainerController.start_learning": {
            "total": 421.8571086,
            "count": 1,
            "self": 1.122124800003462,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.900238,
                    "count": 1,
                    "self": 9.900238
                },
                "TrainerController.advance": {
                    "total": 410.75826689999656,
                    "count": 50746,
                    "self": 1.442770700003905,
                    "children": {
                        "env_step": {
                            "total": 280.57368259999464,
                            "count": 50746,
                            "self": 247.1809074999992,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 32.69295539999676,
                                    "count": 50746,
                                    "self": 2.947243599996657,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 29.745711800000105,
                                            "count": 39838,
                                            "self": 29.745711800000105
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.6998196999986774,
                                    "count": 50745,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 406.3439174000012,
                                            "count": 50745,
                                            "is_parallel": true,
                                            "self": 225.48718950000202,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003381999999998442,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00011390000000055522,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00022429999999928896,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00022429999999928896
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 180.8563896999992,
                                                    "count": 50745,
                                                    "is_parallel": true,
                                                    "self": 6.0047434999948734,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 8.458616600002037,
                                                            "count": 50745,
                                                            "is_parallel": true,
                                                            "self": 8.458616600002037
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 154.0898695999959,
                                                            "count": 50745,
                                                            "is_parallel": true,
                                                            "self": 154.0898695999959
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 12.303160000006374,
                                                            "count": 100953,
                                                            "is_parallel": true,
                                                            "self": 5.908811699997834,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 6.39434830000854,
                                                                    "count": 201906,
                                                                    "is_parallel": true,
                                                                    "self": 6.39434830000854
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 128.741813599998,
                            "count": 100953,
                            "self": 1.8053317999999479,
                            "children": {
                                "process_trajectory": {
                                    "total": 47.082635099998065,
                                    "count": 100953,
                                    "self": 46.993424599998086,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.08921049999997877,
                                            "count": 1,
                                            "self": 0.08921049999997877
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 79.85384669999999,
                                    "count": 48,
                                    "self": 61.043428800000754,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 18.81041789999924,
                                            "count": 1440,
                                            "self": 18.81041789999924
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.999999868639861e-07,
                    "count": 1,
                    "self": 6.999999868639861e-07
                },
                "TrainerController._save_models": {
                    "total": 0.07647819999999683,
                    "count": 1,
                    "self": 0.0025340000000255714,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07394419999997126,
                            "count": 2,
                            "self": 0.07394419999997126
                        }
                    }
                }
            }
        }
    }
}